#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¸‹è½½å™¨ - æ”¯æŒä»Hugging Faceå’ŒModelScopeä¸‹è½½æ¨¡å‹
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from datetime import datetime

class ModelDownloader:
    def __init__(self, model_dir: str = "model"):
        """
        åˆå§‹åŒ–æ¨¡å‹ä¸‹è½½å™¨
        
        Args:
            model_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        """
        self.model_dir = Path(model_dir)
        self.model_dir.mkdir(exist_ok=True)
    
    def check_modelscope_installed(self):
        """æ£€æŸ¥ModelScopeæ˜¯å¦å·²å®‰è£…"""
        try:
            import modelscope
            return True
        except ImportError:
            return False
    
    def check_huggingface_access(self):
        """æ£€æŸ¥Hugging Faceæ˜¯å¦å¯è®¿é—®"""
        try:
            import requests
            test_urls = [
                "https://huggingface.co",
                "https://hf-mirror.com",
                "https://huggingface.co.cn"
            ]
            
            for url in test_urls:
                try:
                    response = requests.get(url, timeout=3)
                    if response.status_code == 200:
                        return True
                except:
                    continue
            
            return False
        except:
            return False
    
    def install_modelscope(self):
        """å®‰è£…ModelScope"""
        print("ğŸ“¦ æ­£åœ¨å®‰è£…ModelScope...")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "modelscope"])
            print("âœ… ModelScopeå®‰è£…æˆåŠŸ")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ ModelScopeå®‰è£…å¤±è´¥: {e}")
            return False
    
    def download_from_huggingface(self, model_name: str, save_dir: Path):
        """ä»Hugging Faceä¸‹è½½æ¨¡å‹"""
        print("ğŸŒ ä»Hugging Faceä¸‹è½½...")
        
        try:
            import requests
            from huggingface_hub import HfApi
            
            # æµ‹è¯•ç½‘ç»œè¿æ¥
            print("ğŸ” æµ‹è¯•ç½‘ç»œè¿æ¥...")
            test_urls = [
                "https://huggingface.co",
                "https://hf-mirror.com",  # å›½å†…é•œåƒ
                "https://huggingface.co.cn"  # å¦ä¸€ä¸ªé•œåƒ
            ]
            
            network_ok = False
            working_url = None
            for url in test_urls:
                try:
                    response = requests.get(url, timeout=5)
                    if response.status_code == 200:
                        print(f"âœ… ç½‘ç»œè¿æ¥æ­£å¸¸: {url}")
                        network_ok = True
                        working_url = url
                        break
                except Exception as e:
                    print(f"âŒ è¿æ¥å¤±è´¥: {url} - {e}")
                    continue
            
            if not network_ok:
                print("âš ï¸  æ‰€æœ‰Hugging Faceé•œåƒéƒ½æ— æ³•è®¿é—®")
                print("ğŸ’¡ å»ºè®®:")
                print("   1. ä½¿ç”¨ModelScopeä¸‹è½½æº")
                print("   2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                print("   3. é…ç½®VPNæˆ–ä»£ç†")
                return False
            
            # è®¾ç½®å·¥ä½œé•œåƒ
            if working_url:
                import os
                os.environ['HF_ENDPOINT'] = working_url
                os.environ['HF_HUB_URL'] = working_url
                print(f"ğŸ”§ ä½¿ç”¨é•œåƒ: {working_url}")
            
            # é…ç½®é•œåƒ
            import os
            # è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨é˜¿é‡Œé•œåƒ
            os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
            os.environ['HF_HUB_URL'] = 'https://hf-mirror.com'
            
            # è®¾ç½®huggingface_hubä½¿ç”¨é˜¿é‡Œé•œåƒ
            try:
                from huggingface_hub import set_http_backend
                set_http_backend("https://hf-mirror.com")
            except:
                pass
            
            print("ğŸ”¤ ä¸‹è½½tokenizer...")
            # å°è¯•ä¸åŒçš„ä»£ç†é…ç½®
            proxy_configs = [
                None,  # æ— ä»£ç†
                {'http': 'http://127.0.0.1:7890', 'https': 'http://127.0.0.1:7890'},  # å¸¸è§ä»£ç†ç«¯å£
                {'http': 'http://127.0.0.1:1080', 'https': 'http://127.0.0.1:1080'},  # å¦ä¸€ä¸ªå¸¸è§ç«¯å£
            ]
            
            for proxies in proxy_configs:
                try:
                    print(f"ğŸ”§ å°è¯•ä»£ç†é…ç½®: {proxies}")
                    tokenizer = AutoTokenizer.from_pretrained(
                        model_name, 
                        trust_remote_code=True,
                        cache_dir=save_dir,
                        local_files_only=False,
                        resume_download=True,
                        proxies=proxies,
                        mirror='aliyun',  # ä½¿ç”¨é˜¿é‡Œé•œåƒ
                        use_auth_token=None
                    )
                    print("âœ… tokenizerä¸‹è½½æˆåŠŸ")
                    break
                except Exception as e:
                    print(f"âŒ ä»£ç†é…ç½®å¤±è´¥: {e}")
                    continue
            else:
                raise Exception("æ‰€æœ‰ä»£ç†é…ç½®éƒ½å¤±è´¥äº†")
            tokenizer.save_pretrained(save_dir)
            print("âœ… tokenizerä¸‹è½½å®Œæˆ")
            
            # ä¸‹è½½æ¨¡å‹
            print("ğŸ§  ä¸‹è½½æ¨¡å‹...")
            # ä½¿ç”¨ç›¸åŒçš„ä»£ç†é…ç½®
            for proxies in proxy_configs:
                try:
                    print(f"ğŸ”§ å°è¯•ä»£ç†é…ç½®ä¸‹è½½æ¨¡å‹: {proxies}")
                    model = AutoModelForCausalLM.from_pretrained(
                        model_name,
                        trust_remote_code=True,
                        cache_dir=save_dir,
                        torch_dtype=torch.float16,
                        device_map="auto" if torch.cuda.is_available() else None,
                        local_files_only=False,
                        resume_download=True,
                        proxies=proxies,
                        mirror='aliyun',  # ä½¿ç”¨é˜¿é‡Œé•œåƒ
                        use_auth_token=None
                    )
                    print("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ")
                    break
                except Exception as e:
                    print(f"âŒ æ¨¡å‹ä¸‹è½½ä»£ç†é…ç½®å¤±è´¥: {e}")
                    continue
            else:
                raise Exception("æ‰€æœ‰æ¨¡å‹ä¸‹è½½ä»£ç†é…ç½®éƒ½å¤±è´¥äº†")
            model.save_pretrained(save_dir)
            print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ")
            
            return True
            
        except requests.exceptions.ConnectionError as e:
            print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. ä½¿ç”¨ModelScopeä¸‹è½½æº")
            print("   3. é…ç½®ä»£ç†æˆ–VPN")
            return False
        except requests.exceptions.Timeout as e:
            print(f"âŒ ç½‘ç»œè¶…æ—¶: {e}")
            print("ğŸ’¡ å»ºè®®ä½¿ç”¨ModelScopeä¸‹è½½æº")
            return False
        except Exception as e:
            print(f"âŒ Hugging Faceä¸‹è½½å¤±è´¥: {e}")
            print("ğŸ”„ å°è¯•ä½¿ç”¨å‘½ä»¤è¡Œä¸‹è½½...")
            return self.download_with_cli(model_name, save_dir)
    
    def download_with_cli(self, model_name: str, save_dir: Path):
        """ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ä¸‹è½½æ¨¡å‹"""
        print("ğŸ”§ ä½¿ç”¨å‘½ä»¤è¡Œä¸‹è½½...")
        
        try:
            # é¦–å…ˆæ£€æŸ¥git lfsæ˜¯å¦å®‰è£…
            print("ğŸ” æ£€æŸ¥git lfs...")
            result = subprocess.run("git lfs version", shell=True, capture_output=True, text=True)
            if result.returncode != 0:
                print("âš ï¸  git lfsæœªå®‰è£…ï¼Œå°è¯•å®‰è£…...")
                try:
                    subprocess.run("curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash", shell=True)
                    subprocess.run("sudo apt-get install git-lfs", shell=True)
                    subprocess.run("git lfs install", shell=True)
                    print("âœ… git lfså®‰è£…æˆåŠŸ")
                except Exception as e:
                    print(f"âŒ git lfså®‰è£…å¤±è´¥: {e}")
                    print("ğŸ”„ è·³è¿‡git lfsï¼Œç›´æ¥ä½¿ç”¨git...")
            
            # å°è¯•ä¸åŒçš„é•œåƒURL
            mirror_urls = [
                f"https://huggingface.co/{model_name}",
                f"https://hf-mirror.com/{model_name}",  # é˜¿é‡Œäº‘é•œåƒ
                f"https://huggingface.co.cn/{model_name}",
                f"https://modelscope.cn/models/{model_name}"  # ModelScopeé•œåƒ
            ]
            
            # å°è¯•ä½¿ç”¨git cloneï¼ˆä¸ä½¿ç”¨lfsï¼‰
            print("ğŸ“¥ ä½¿ç”¨git cloneä¸‹è½½...")
            for url in mirror_urls:
                try:
                    print(f"ğŸ”§ å°è¯•é•œåƒ: {url}")
                    cmd = f"git clone {url} {save_dir}"
                    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        print("âœ… git cloneä¸‹è½½æˆåŠŸ")
                        return True
                    else:
                        print(f"âŒ git cloneå¤±è´¥: {result.stderr}")
                except Exception as e:
                    print(f"âŒ git cloneå¼‚å¸¸: {e}")
                    continue
            
            # å¦‚æœgitå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨wget
            print("ğŸ“¥ å°è¯•ä½¿ç”¨wgetä¸‹è½½...")
            for url in mirror_urls:
                try:
                    print(f"ğŸ”§ å°è¯•wgeté•œåƒ: {url}")
                    # ä½¿ç”¨æ›´ç®€å•çš„wgetå‘½ä»¤
                    cmd = f"wget -r -np -nH --cut-dirs=2 -R 'index.html*' {url}/tree/main -P {save_dir}"
                    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        print("âœ… wgetä¸‹è½½æˆåŠŸ")
                        return True
                    else:
                        print(f"âŒ wgetå¤±è´¥: {result.stderr}")
                except Exception as e:
                    print(f"âŒ wgetå¼‚å¸¸: {e}")
                    continue
            
            # æœ€åå°è¯•ä½¿ç”¨curl
            print("ğŸ“¥ å°è¯•ä½¿ç”¨curlä¸‹è½½...")
            for url in mirror_urls:
                try:
                    print(f"ğŸ”§ å°è¯•curlé•œåƒ: {url}")
                    cmd = f"curl -L -o {save_dir}/model.zip {url}/archive/main.zip"
                    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        print("âœ… curlä¸‹è½½æˆåŠŸ")
                        # è§£å‹æ–‡ä»¶
                        subprocess.run(f"unzip {save_dir}/model.zip -d {save_dir}", shell=True)
                        return True
                    else:
                        print(f"âŒ curlå¤±è´¥: {result.stderr}")
                except Exception as e:
                    print(f"âŒ curlå¼‚å¸¸: {e}")
                    continue
            
            print("âŒ æ‰€æœ‰å‘½ä»¤è¡Œä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥äº†")
            print("ğŸ’¡ å»ºè®®:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. ä½¿ç”¨ModelScopeä¸‹è½½æº")
            print("   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
            return False
            
        except Exception as e:
            print(f"âŒ å‘½ä»¤è¡Œä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_from_modelscope(self, model_name: str, save_dir: Path):
        """ä»ModelScopeä¸‹è½½æ¨¡å‹"""
        print("ğŸ¢ ä»ModelScopeä¸‹è½½...")
        
        try:
            # ä½¿ç”¨modelscopeçš„Python APIä¸‹è½½
            from modelscope import snapshot_download
            
            print(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
            print(f"ä¿å­˜åˆ°: {save_dir}")
            
            # éªŒè¯æ¨¡å‹åç§°æ ¼å¼
            if '/' not in model_name:
                print(f"âŒ ModelScopeæ¨¡å‹åç§°æ ¼å¼é”™è¯¯: {model_name}")
                print("ğŸ’¡ ModelScopeæ¨¡å‹åç§°æ ¼å¼åº”ä¸º: namespace/name")
                print("   ä¾‹å¦‚: YIRONGCHEN/SoulChat2.0-Yi-1.5-9B")
                return False
            
            # ä½¿ç”¨snapshot_download API
            downloaded_path = snapshot_download(
                model_id=model_name,
                cache_dir=str(save_dir),
                local_dir=str(save_dir)
            )
            
            print(f"âœ… ModelScopeä¸‹è½½å®Œæˆ: {downloaded_path}")
            return True
                
        except ImportError:
            print("âŒ ModelScopeæœªå®‰è£…ï¼Œå°è¯•å®‰è£…...")
            if self.install_modelscope():
                # é‡æ–°å°è¯•ä¸‹è½½
                try:
                    from modelscope import snapshot_download
                    
                    print(f"é‡æ–°å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
                    downloaded_path = snapshot_download(
                        model_id=model_name,
                        cache_dir=str(save_dir),
                        local_dir=str(save_dir)
                    )
                    
                    print(f"âœ… ModelScopeä¸‹è½½å®Œæˆ: {downloaded_path}")
                    return True
                except Exception as e:
                    print(f"âŒ ModelScopeä¸‹è½½å¤±è´¥: {e}")
                    return False
            else:
                return False
                
        except Exception as e:
            print(f"âŒ ModelScopeä¸‹è½½å¼‚å¸¸: {e}")
            return False
    
    def download_model(self, model_name: str, source: str = "auto"):
        """
        ä¸‹è½½æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            source: ä¸‹è½½æº ("huggingface", "modelscope", "auto")
        """
        # åˆ›å»ºä¿å­˜ç›®å½• - ä½¿ç”¨æ¨¡å‹åç§°çš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºç›®å½•å
        if '/' in model_name:
            save_dir_name = model_name.split('/')[-1]
        else:
            save_dir_name = model_name
        
        save_dir = self.model_dir / save_dir_name
        save_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
        print(f"ğŸ“ ä¿å­˜ç›®å½•: {save_dir}")
        print(f"ğŸŒ ä¸‹è½½æº: {source}")
        print()
        
        success = False
        
        if source == "huggingface":
            success = self.download_from_huggingface(model_name, save_dir)
        elif source == "modelscope":
            if not self.check_modelscope_installed():
                if not self.install_modelscope():
                    return None
            success = self.download_from_modelscope(model_name, save_dir)
        elif source == "auto":
            # è‡ªåŠ¨é€‰æ‹©ä¸‹è½½æº
            print("ğŸ”„ è‡ªåŠ¨é€‰æ‹©ä¸‹è½½æº...")
            
            # æ£€æµ‹ç½‘ç»œç¯å¢ƒ
            print("ğŸ” æ£€æµ‹ç½‘ç»œç¯å¢ƒ...")
            hf_accessible = self.check_huggingface_access()
            
            if hf_accessible:
                print("ğŸŒ Hugging Faceå¯è®¿é—®ï¼Œä¼˜å…ˆå°è¯•...")
                success = self.download_from_huggingface(model_name, save_dir)
                
                if not success:
                    print("ğŸ”„ Hugging Faceå¤±è´¥ï¼Œå°è¯•ModelScope...")
                    if not self.check_modelscope_installed():
                        if not self.install_modelscope():
                            print("âŒ ModelScopeå®‰è£…å¤±è´¥")
                            return None
                    success = self.download_from_modelscope(model_name, save_dir)
            else:
                print("ğŸŒ Hugging Faceä¸å¯è®¿é—®ï¼Œç›´æ¥ä½¿ç”¨ModelScope...")
                if not self.check_modelscope_installed():
                    if not self.install_modelscope():
                        print("âŒ ModelScopeå®‰è£…å¤±è´¥")
                        return None
                success = self.download_from_modelscope(model_name, save_dir)
        
        if success:
            # ä¿å­˜æ¨¡å‹ä¿¡æ¯
            model_info = {
                "name": model_name,
                "source": source,
                "local_path": str(save_dir),
                "download_time": str(datetime.now()),
                "model_type": "causal_lm"
            }
            
            with open(save_dir / "model_info.json", "w", encoding="utf-8") as f:
                json.dump(model_info, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆï¼ä¿å­˜åœ¨: {save_dir}")
            return str(save_dir)
        else:
            print(f"âŒ æ‰€æœ‰ä¸‹è½½æºéƒ½å¤±è´¥äº†")
            return None
    
    def list_downloaded_models(self):
        """åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹"""
        print("ğŸ“š å·²ä¸‹è½½çš„æ¨¡å‹:")
        print("=" * 40)
        
        if not self.model_dir.exists():
            print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
            return []
        
        models = []
        for i, model_path in enumerate(self.model_dir.iterdir(), 1):
            if model_path.is_dir():
                info_file = model_path / "model_info.json"
                if info_file.exists():
                    try:
                        with open(info_file, "r", encoding="utf-8") as f:
                            info = json.load(f)
                        print(f"{i}. ğŸ“ {model_path.name}")
                        print(f"   åŸå§‹åç§°: {info.get('name', 'Unknown')}")
                        print(f"   ä¸‹è½½æº: {info.get('source', 'Unknown')}")
                        print(f"   ä¸‹è½½æ—¶é—´: {info.get('download_time', 'Unknown')}")
                        
                        # è®¡ç®—æ¨¡å‹å¤§å°
                        size = self.get_model_size(model_path)
                        print(f"   å¤§å°: {size}")
                        
                        models.append(str(model_path))
                    except:
                        print(f"{i}. ğŸ“ {model_path.name} (ä¿¡æ¯æ–‡ä»¶æŸå)")
                        models.append(str(model_path))
                else:
                    print(f"{i}. ğŸ“ {model_path.name} (æ— ä¿¡æ¯æ–‡ä»¶)")
                    models.append(str(model_path))
        
        return models
    
    def get_model_size(self, model_path: Path):
        """è·å–æ¨¡å‹å¤§å°"""
        try:
            total_size = 0
            file_count = 0
            for file_path in model_path.rglob('*'):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
                    file_count += 1
            
            # è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
            if total_size < 1024:
                return f"{total_size} B"
            elif total_size < 1024 * 1024:
                return f"{total_size / 1024:.1f} KB"
            elif total_size < 1024 * 1024 * 1024:
                return f"{total_size / (1024 * 1024):.1f} MB"
            else:
                return f"{total_size / (1024 * 1024 * 1024):.1f} GB"
        except:
            return "æœªçŸ¥"
    
    def delete_model(self, model_name: str):
        """åˆ é™¤æ¨¡å‹"""
        model_path = self.model_dir / model_name
        
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_name}")
            return False
        
        if not model_path.is_dir():
            print(f"âŒ ä¸æ˜¯æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•: {model_name}")
            return False
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        info_file = model_path / "model_info.json"
        if info_file.exists():
            try:
                with open(info_file, "r", encoding="utf-8") as f:
                    info = json.load(f)
                print(f"ğŸ—‘ï¸  å‡†å¤‡åˆ é™¤æ¨¡å‹:")
                print(f"   åç§°: {info.get('name', model_name)}")
                print(f"   ä¸‹è½½æº: {info.get('source', 'Unknown')}")
                print(f"   ä¸‹è½½æ—¶é—´: {info.get('download_time', 'Unknown')}")
                print(f"   å¤§å°: {self.get_model_size(model_path)}")
            except:
                print(f"ğŸ—‘ï¸  å‡†å¤‡åˆ é™¤æ¨¡å‹: {model_name}")
        else:
            print(f"ğŸ—‘ï¸  å‡†å¤‡åˆ é™¤æ¨¡å‹: {model_name}")
        
        # ç¡®è®¤åˆ é™¤
        confirm = input("âš ï¸  ç¡®å®šè¦åˆ é™¤è¿™ä¸ªæ¨¡å‹å—ï¼Ÿ(è¾“å…¥ 'DELETE' ç¡®è®¤): ").strip()
        if confirm != "DELETE":
            print("âŒ åˆ é™¤å·²å–æ¶ˆ")
            return False
        
        try:
            import shutil
            shutil.rmtree(model_path)
            print(f"âœ… æ¨¡å‹åˆ é™¤æˆåŠŸ: {model_name}")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            return False
    
    def delete_model_by_index(self, index: int):
        """æ ¹æ®ç´¢å¼•åˆ é™¤æ¨¡å‹"""
        models = []
        for model_path in self.model_dir.iterdir():
            if model_path.is_dir():
                models.append(model_path.name)
        
        if index < 1 or index > len(models):
            print(f"âŒ æ— æ•ˆçš„ç´¢å¼•: {index}")
            return False
        
        model_name = models[index - 1]
        return self.delete_model(model_name)

def main():
    """ä¸»å‡½æ•°"""
    downloader = ModelDownloader()
    
    print("ğŸš€ æ¨¡å‹ä¸‹è½½å™¨")
    print("=" * 50)
    print("æ”¯æŒçš„ä¸‹è½½æº:")
    print("- ModelScope: é˜¿é‡Œäº‘æ¨¡å‹ç¤¾åŒºï¼ˆæ¨èï¼Œå›½å†…ç½‘ç»œç¨³å®šï¼‰")
    print("- Hugging Face: å…¨çƒæœ€å¤§çš„æ¨¡å‹ç¤¾åŒº")
    print()
    print("ğŸ’¡ å»ºè®®:")
    print("- å›½å†…ç”¨æˆ·ä¼˜å…ˆä½¿ç”¨ModelScope")
    print("- å¦‚æœç½‘ç»œä¸ç¨³å®šï¼Œé€‰æ‹©ModelScopeä¸‹è½½æº")
    print("- å¦‚æœHugging Faceæ— æ³•è®¿é—®ï¼Œç¨‹åºä¼šè‡ªåŠ¨é€‰æ‹©ModelScope")
    print()
    print("ç¤ºä¾‹æ¨¡å‹åç§°:")
    print("ModelScopeï¼ˆæ¨èï¼‰:")
    print("- YIRONGCHEN/SoulChat2.0-Yi-1.5-9B")
    print("- qwen/Qwen2.5-7B-Instruct")
    print("- THUDM/chatglm3-6b")
    print("- YIRONGCHEN/SoulChat2.0-Llama-3.1-8B")
    print()
    print("Hugging Face:")
    print("- microsoft/DialoGPT-medium")
    print("- Qwen/Qwen2.5-7B-Instruct")
    print("- THUDM/chatglm3-6b")
    print("- baichuan-inc/Baichuan2-7B-Chat")
    print()
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ä¸‹è½½æ¨¡å‹ (è‡ªåŠ¨é€‰æ‹©æº)")
        print("2. ä»Hugging Faceä¸‹è½½")
        print("3. ä»ModelScopeä¸‹è½½")
        print("4. æŸ¥çœ‹å·²ä¸‹è½½æ¨¡å‹")
        print("5. åˆ é™¤æ¨¡å‹")
        print("6. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
        
        if choice == "1":
            model_name = input("è¯·è¾“å…¥æ¨¡å‹åç§°: ").strip()
            if model_name:
                downloader.download_model(model_name, "auto")
            else:
                print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                
        elif choice == "2":
            model_name = input("è¯·è¾“å…¥Hugging Faceæ¨¡å‹åç§°: ").strip()
            if model_name:
                downloader.download_model(model_name, "huggingface")
            else:
                print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                
        elif choice == "3":
            model_name = input("è¯·è¾“å…¥ModelScopeæ¨¡å‹åç§°: ").strip()
            if model_name:
                downloader.download_model(model_name, "modelscope")
            else:
                print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                
        elif choice == "4":
            downloader.list_downloaded_models()
            
        elif choice == "5":
            print("\nğŸ—‘ï¸  åˆ é™¤æ¨¡å‹")
            print("=" * 30)
            models = downloader.list_downloaded_models()
            
            if not models:
                print("âŒ æ²¡æœ‰å¯åˆ é™¤çš„æ¨¡å‹")
                continue
            
            print("\né€‰æ‹©åˆ é™¤æ–¹å¼:")
            print("1. æŒ‰ç´¢å¼•åˆ é™¤")
            print("2. æŒ‰åç§°åˆ é™¤")
            print("3. è¿”å›ä¸»èœå•")
            
            delete_choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
            
            if delete_choice == "1":
                try:
                    index = int(input("è¯·è¾“å…¥æ¨¡å‹ç´¢å¼•: ").strip())
                    downloader.delete_model_by_index(index)
                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
                    
            elif delete_choice == "2":
                model_name = input("è¯·è¾“å…¥æ¨¡å‹åç§°: ").strip()
                if model_name:
                    downloader.delete_model(model_name)
                else:
                    print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
                    
            elif delete_choice == "3":
                continue
            else:
                print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            
        elif choice == "6":
            print("ğŸ‘‹ å†è§ï¼")
            break
            
        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main() 